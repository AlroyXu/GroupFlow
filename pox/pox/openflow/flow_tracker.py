#!/usr/bin/python
# -*- coding: utf-8 -*-

"""
A POX module which periodically queries the network to learn the following information:
- Bandwidth usage on all links in the network (using both FlowStats on the transmission side, and PortStats on the
  receive side)
- Number of flow table installations on all switches in the network

Depends on openflow.discovery

Created on Oct 16, 2013
@author: alexcraig
"""

# POX dependencies
from pox.openflow.discovery import Discovery
from pox.core import core
from pox.lib.revent import *
from pox.lib.util import dpid_to_str
import pox.lib.packet as pkt
from pox.lib.packet.igmpv3 import *   # Required for various IGMP variable constants
from pox.lib.packet.ethernet import *
import pox.openflow.libopenflow_01 as of
from pox.lib.addresses import IPAddr, EthAddr
from pox.lib.recoco import Timer
import time
import datetime

log = core.getLogger()

# Note: These constants provide default values, which can be overridden by passing command
# line parameters when the module launches
OUTPUT_PEAK_USAGE = False
AVERAGE_SMOOTHING_FACTOR = 0.7
LINK_MAX_BANDWIDTH_MbPS = 30 # MegaBits per second
LINK_CONGESTION_THRESHOLD_MbPS = 0.95 * LINK_MAX_BANDWIDTH_MbPS
PERIODIC_QUERY_INTERVAL = 2 # Seconds

class FlowTrackedSwitch(EventMixin):
    """Class used to manage statistics querying and processing for a single OpenFlow switch. The FlowTracker module
    implements bandwidth tracking by managing a map of these objects."""

    def __init__(self, flow_tracker):
        """Initializes a new FlowTrackedSwitch"""
        self.flow_tracker = flow_tracker
        self.tracked_ports = [] # Only port numbers in this list will have their utilization tracked
        self.connection = None
        self.is_connected = False
        self.dpid = None
        self._listeners = None
        self._connection_time = None

        self._last_flow_stats_query_send_time = None
        self._last_flow_stats_query_response_time = None
        self._last_flow_stats_query_network_time = None
        self._last_flow_stats_query_processing_time = None
        self._last_flow_stats_query_total_time = None

        self._last_port_stats_query_send_time = None
        self._last_port_stats_query_processing_time = None

        self.num_flows = 0

        # Flow maps record transmission statistics based on FlowStats queries
        # Maps are keyed by port number
        # Each map contains a map of byte/bandwidth counts keyed by flow cookie (0 used for flows with no cookie)
        self.flow_total_byte_count = {}
        self.flow_interval_byte_count = {}
        self.flow_interval_bandwidth_Mbps = {}
        self.flow_average_bandwidth_Mbps = {}
        self.flow_average_switch_load = 0

        # Port maps record reception statistics based on PortStats queries
        # Maps are keyed by port number
        # Byte/bandwidth counts are only recorded on a per port basis
        self.port_total_byte_count = {}
        self.port_interval_byte_count = {}
        self.port_interval_bandwidth_Mbps = {}
        self.port_average_bandwidth_Mbps = {}
        self.port_average_switch_load = 0

        self._periodic_query_timer = None

    def __repr__(self):
        """Returns string representation of the switch's data-plane identifier."""
        return dpid_to_str(self.dpid)

    def ignore_connection(self):
        """Disconnects listener methods on statistics queries, and stops the periodic query timer."""
        if self.connection is not None:
            log.debug('Disconnect %s' % (self.connection, ))
            self.connection.removeListeners(self._listeners)
            self.connection = None
            self.is_connected = False
            self._connection_time = None
            self._listeners = None
            self._last_port_stats_query_response_time = None
            self._last_flow_stats_query_response_time = None

            if self._periodic_query_timer is not None:
                self._periodic_query_timer.cancel()
                self._periodic_query_timer = None

    def listen_on_connection(self, connection):
        """Configures listener methods to handle query responses, and starts the periodic query timer."""
        if self.dpid is None:
            self.dpid = connection.dpid
        assert self.dpid == connection.dpid

        log.debug('Connect %s' % (connection, ))
        self.connection = connection
        self.is_connected = True
        self._listeners = self.listenTo(connection)
        self._connection_time = time.time()
        self._last_flow_stats_query_response_time = None
        self._last_port_stats_query_response_time = None
        self._periodic_query_timer = Timer(self.flow_tracker.periodic_query_interval_seconds, self.launch_stats_query,
            recurring=True)

    def _handle_ConnectionDown(self, event):
        """Handler called when a ConnectionDown event is generated by the POX core."""
        self.ignore_connection()

    def set_tracked_ports(self, tracked_ports):
        """Sets the port numbers on which bandwidth utilization should be tracked for this switch."""
        self.tracked_ports = tracked_ports
        log.debug('Switch ' + dpid_to_str(self.dpid) + ' set tracked ports: ' + str(tracked_ports))
        # Delete any stored state on ports which are no longer tracked
        keys_to_del = []
        for port_no in self.flow_interval_byte_count:
            if not port_no in self.tracked_ports:
                keys_to_del.append(port_no)

        for key in keys_to_del:
            del self.flow_total_byte_count[key]
            del self.flow_interval_byte_count[key]
            del self.flow_interval_bandwidth_Mbps[key]
            del self.flow_average_bandwidth_Mbps[key]

            del self.port_total_byte_count[key]
            del self.port_interval_byte_count[key]
            del self.port_interval_bandwidth_Mbps[key]
            del self.port_average_bandwidth_Mbps[key]

    def launch_stats_query(self):
        """Sends an OpenFlow FlowStatsRequest and PortStatsRequest to the switch associated with this object."""
        if self.is_connected:
            self.connection.send(of.ofp_stats_request(body=of.ofp_flow_stats_request()))
            self._last_flow_stats_query_send_time = time.time()
            self.connection.send(of.ofp_stats_request(body=of.ofp_port_stats_request()))
            self._last_port_stats_query_send_time = time.time()
            log.debug('Sent flow and port stats requests to switch: ' + dpid_to_str(self.dpid))

    def process_port_stats(self, stats, reception_time):
        """Processes a PortStats response to a PortStatsRequest.

        Port stats are processed to determine bandwidth utilization from the receiving side of a link. This method was
        chosen to overcome limitations in Mininet's link emulation technique, which causes FlowStats to overestimate
        the utilization of a link when a link becomes congested. PortStats should always give an accurate count of the
        bytes received on a particular port even in congestion conditions, but the utilization cannot be determined on
        a per-flow basis using PortStats messages.

        An exponential moving average is used to smooth bandwidth estimates, where the alpha of the exponential average
        is set by flow_tracker.avg_smooth_factor.
        """
        if not self.is_connected:
            return

        log.debug('== PortStatsReceived - Switch: ' + dpid_to_str(self.dpid) + ' - Time: ' + str(reception_time))

        # Clear byte counts for this interval
        for port in self.port_interval_byte_count:
            self.port_interval_byte_count[port] = 0
        curr_event_byte_count = {}

        # Check for new ports on the switch
        ports = self.connection.features.ports
        invalid_stat_ports = []     # Ports added to this list will not have their bandwidth averages updated for this interval
        for port in ports:
            if port.port_no == of.OFPP_LOCAL or port.port_no == of.OFPP_CONTROLLER:
                continue

            if not port.port_no in self.tracked_ports:
                continue

            if not port.port_no in self.port_total_byte_count:
                invalid_stat_ports.append(
                    port.port_no) # Port bandwidth statistics are not updated on the first interval the port appears
                self.port_total_byte_count[port.port_no] = 0
                self.port_interval_byte_count[port.port_no] = 0
                self.port_interval_bandwidth_Mbps[port.port_no] = 0
                self.port_average_bandwidth_Mbps[port.port_no] = 0

        # Record the number of bytes transmitted through each port for this monitoring interval
        for port_stat in stats:
            if port_stat.port_no in self.tracked_ports:
                if port_stat.port_no in curr_event_byte_count:
                    curr_event_byte_count[port_stat.port_no] = curr_event_byte_count[
                                                               port_stat.port_no] + port_stat.rx_bytes
                else:
                    curr_event_byte_count[port_stat.port_no] = port_stat.rx_bytes

        # Determine the number of new bytes that appeared this interval, and set the flow removed flag to true if
        # any port count is lower than in the previous interval
        for port_num in curr_event_byte_count:
            if port_num in self.tracked_ports:
                if not port_num in self.port_total_byte_count:
                    # Port has never appeared before
                    self.port_total_byte_count[port_num] = curr_event_byte_count[port_num]
                    self.port_interval_byte_count[port_num] = curr_event_byte_count[port_num]
                elif curr_event_byte_count[port_num] < self.port_total_byte_count[port_num]:
                    # Byte count for this monitoring interval is less than previous interval, flow must have been removed
                    self.port_total_byte_count[port_num] = curr_event_byte_count[port_num]
                    self.port_interval_byte_count[port_num] = 0
                    invalid_stat_ports.append(port_num)
                else:
                    self.port_interval_byte_count[port_num] = (curr_event_byte_count[port_num]
                            - self.port_total_byte_count[port_num])
                    self.port_total_byte_count[port_num] = curr_event_byte_count[port_num]

        # Skip further processing if this was the first measurement interval, or if the measurement interval had an unreasonable duration
        if self._last_port_stats_query_response_time is None:
            self._last_port_stats_query_response_time = reception_time
            return
        interval_len = reception_time - self._last_port_stats_query_response_time
        if (interval_len < (0.5 * self.flow_tracker.periodic_query_interval_seconds)
                or interval_len > (2 * self.flow_tracker.periodic_query_interval_seconds)):
            self._last_port_stats_query_response_time = reception_time
            return

        # Update bandwidth estimates for valid ports
        for port_num in self.port_interval_byte_count:
            if port_num in invalid_stat_ports:
                continue

            # Update instant bandwidth
            self.port_interval_bandwidth_Mbps[port_num] = ((self.port_interval_byte_count[
                                                            port_num] * 8.0) / 1048576.0) / (interval_len)
            # Update running average bandwidth
            if port_num in self.port_average_bandwidth_Mbps:
                self.port_average_bandwidth_Mbps[port_num] = (self.flow_tracker.avg_smooth_factor *
                                                              self.port_interval_bandwidth_Mbps[port_num]) +\
                                                             ((1 - self.flow_tracker.avg_smooth_factor) *
                                                              self.port_average_bandwidth_Mbps[port_num])
            else:
                self.port_average_bandwidth_Mbps[port_num] = self.port_interval_bandwidth_Mbps[port_num]

        port_average_switch_load = 0
        for port_num in self.port_average_bandwidth_Mbps:
            port_average_switch_load += self.port_average_bandwidth_Mbps[port_num]
        self.port_average_switch_load = port_average_switch_load

        # Update last response time
        complete_processing_time = time.time()
        self._last_port_stats_query_processing_time = complete_processing_time - reception_time
        self._last_port_stats_query_total_time = complete_processing_time - self._last_port_stats_query_send_time

        # Print log information to file
        if not self.flow_tracker._log_file is None:
            self.flow_tracker._log_file.write('PortStats Switch:' + dpid_to_str(self.dpid) + ' IntervalLen:' + str(
                interval_len) + ' IntervalEndTime:' + str(reception_time) + ' AvgSwitchLoad:' + str(
                self.port_average_switch_load) + '\n')

            for port_num in self.port_interval_bandwidth_Mbps:
                self.flow_tracker._log_file.write(
                    'Port:' + str(port_num) + ' BytesThisInterval:' + str(self.port_interval_byte_count[port_num])
                    + ' InstBandwidth:' + str(self.port_interval_bandwidth_Mbps[port_num]) + ' AvgBandwidth:' + str(
                        self.port_average_bandwidth_Mbps[port_num]) + '\n')
                if(self.port_average_bandwidth_Mbps[port_num] >= (self.flow_tracker.link_cong_threshold)):
                    log.warn('Congested link detected! RecvSw:' + dpid_to_str(self.dpid) + ' Port:' + str(port_num))

            self.flow_tracker._log_file.write('\n')

        self._last_port_stats_query_response_time = reception_time


    def process_flow_stats(self, stats, reception_time):
        """Processes a FlowStats response to a FlowStatsRequest.

        Flow stats are processed to determine bandwidth utilization from the transmission side of a link. This method
        can produce inaccurate measurements when using Mininet link emulation. In particular, the statistics returned
        by emulated switches will not properly detect dropped packets, and the byte counts returned in FlowStats
        responses will overestimate the actual bytes forwarded when the link becomes congested. FlowStats are recorded
        on a per-flow basis, allowing the module the percentage of link utilization contributed by each flow in the
        network. Flows are differentiated by their controller assigned flow cookie. Flows with no cookie default to a
        cookie value of 0, and the FlowTracker module will consider all flows without a cookie as a single flow with
        cookie value 0.

        An exponential moving average is used to smooth bandwidth estimates, where the alpha of the exponential average
        is set by flow_tracker.avg_smooth_factor.
        """
        if not self.is_connected:
            return

        log.debug('== FlowStatsReceived - Switch: ' + dpid_to_str(self.dpid) + ' - Time: ' + str(reception_time))
        self._last_flow_stats_query_network_time = reception_time - self._last_flow_stats_query_send_time

        # Clear byte counts for this interval
        for port in self.flow_interval_byte_count:
            self.flow_interval_byte_count[port] = {}
        self.num_flows = 0

        curr_event_byte_count = {}

        # Check for new ports on the switch
        ports = self.connection.features.ports
        for port in ports:
            if port.port_no == of.OFPP_LOCAL or port.port_no == of.OFPP_CONTROLLER:
                continue

            if not port.port_no in self.tracked_ports:
                continue

            if not port.port_no in self.flow_total_byte_count:
                self.flow_total_byte_count[port.port_no] = {}
                self.flow_interval_byte_count[port.port_no] = {}
                self.flow_interval_bandwidth_Mbps[port.port_no] = {}
                self.flow_average_bandwidth_Mbps[port.port_no] = {}

        # Record the number of bytes transmitted through each port for this monitoring interval
        for flow_stat in stats:
            self.num_flows = self.num_flows + 1
            for action in flow_stat.actions:
                if isinstance(action, of.ofp_action_output):
                    if action.port in self.tracked_ports:
                        # log.info('Got flow on tracked port with cookie: ' + str(flow_stat.cookie))
                        if action.port in curr_event_byte_count:
                            if flow_stat.cookie in curr_event_byte_count[action.port]:
                                curr_event_byte_count[action.port][flow_stat.cookie] = \
                                        curr_event_byte_count[action.port][flow_stat.cookie] + flow_stat.byte_count
                            else:
                                curr_event_byte_count[action.port][flow_stat.cookie] = flow_stat.byte_count
                        else:
                            curr_event_byte_count[action.port] = {}
                            curr_event_byte_count[action.port][flow_stat.cookie] = flow_stat.byte_count

        # Determine the number of new bytes that appeared this interval, and set the flow removed flag to true if
        # any port count is lower than in the previous interval
        for port_num in curr_event_byte_count:
            if port_num in self.tracked_ports:
                if not port_num in self.flow_total_byte_count:
                    # Port has never appeared before
                    self.flow_total_byte_count[port_num] = {}
                    self.flow_interval_byte_count[port_num] = {}
                    for flow_cookie in curr_event_byte_count[port_num]:
                        self.flow_total_byte_count[port_num][flow_cookie] = curr_event_byte_count[port_num][flow_cookie]
                        self.flow_interval_byte_count[port_num][flow_cookie] = curr_event_byte_count[port_num][
                                                                               flow_cookie]
                else:
                    for flow_cookie in curr_event_byte_count[port_num]:
                        if flow_cookie not in self.flow_total_byte_count[port_num]:
                            # Flow has not appeared before
                            self.flow_total_byte_count[port_num][flow_cookie] = curr_event_byte_count[port_num][
                                                                                flow_cookie]
                            self.flow_interval_byte_count[port_num][flow_cookie] = curr_event_byte_count[port_num][
                                                                                   flow_cookie]
                        else:
                            self.flow_interval_byte_count[port_num][flow_cookie] = (curr_event_byte_count[port_num][
                                                                                   flow_cookie] -
                                                                                   self.flow_total_byte_count[port_num][
                                                                                   flow_cookie])
                            self.flow_total_byte_count[port_num][flow_cookie] = curr_event_byte_count[port_num][
                                                                                flow_cookie]

                            # TODO: Handle the case where a flow reports less bytes forwarded than the previous interval
                            # (not sure if this can ever actually happen)

        # Remove counters for flows that were removed in this interval
        flows_to_remove = []
        for port_num in self.flow_total_byte_count:
            for flow_cookie in self.flow_total_byte_count[port_num]:
                if port_num not in curr_event_byte_count or flow_cookie not in curr_event_byte_count[port_num]:
                    flows_to_remove.append((port_num, flow_cookie))
        for removal in flows_to_remove:
            log.info('Removing bandwidth counters for port: ' + str(removal[0]) + ' flow cookie: ' + str(removal[1]))
            if removal[1] in self.flow_interval_byte_count[removal[0]]:
                del self.flow_interval_byte_count[removal[0]][removal[1]]
            if removal[1] in self.flow_total_byte_count[removal[0]]:
                del self.flow_total_byte_count[removal[0]][removal[1]]
            if removal[1] in self.flow_interval_bandwidth_Mbps[removal[0]]:
                del self.flow_interval_bandwidth_Mbps[removal[0]][removal[1]]
            if removal[1] in self.flow_average_bandwidth_Mbps[removal[0]]:
                del self.flow_average_bandwidth_Mbps[removal[0]][removal[1]]

        # Skip further processing if this was the first measurement interval, or if the measurement interval had an unreasonable duration
        if self._last_flow_stats_query_response_time is None:
            self._last_flow_stats_query_response_time = reception_time
            return
        interval_len = reception_time - self._last_flow_stats_query_response_time
        if interval_len < (0.5 * self.flow_tracker.periodic_query_interval_seconds) or interval_len > (
        2 * self.flow_tracker.periodic_query_interval_seconds):
            self._last_flow_stats_query_response_time = reception_time
            return

        # Update bandwidth estimates
        for port_num in self.flow_interval_byte_count:
            if port_num not in self.flow_interval_bandwidth_Mbps:
                self.flow_interval_bandwidth_Mbps[port_num] = {}
                self.flow_average_bandwidth_Mbps[port_num] = {}

            for flow_cookie in self.flow_interval_byte_count[port_num]:
                if flow_cookie not in self.flow_interval_bandwidth_Mbps[port_num]:
                    self.flow_interval_bandwidth_Mbps[port_num][flow_cookie] = 0
                    self.flow_average_bandwidth_Mbps[port_num][flow_cookie] = 0

                # Update instant bandwidth
                self.flow_interval_bandwidth_Mbps[port_num][flow_cookie] = ((self.flow_interval_byte_count[port_num][
                                                                             flow_cookie] * 8.0) / 1048576.0) / (
                interval_len)
                # Update running average bandwidth
                self.flow_average_bandwidth_Mbps[port_num][flow_cookie] = min(
                    (self.flow_tracker.avg_smooth_factor * self.flow_interval_bandwidth_Mbps[port_num][flow_cookie]) +\
                    (
                    (1 - self.flow_tracker.avg_smooth_factor) * self.flow_average_bandwidth_Mbps[port_num][flow_cookie])
                    , self.flow_tracker.link_max_bw)

        flow_average_switch_load = 0
        for port_num in self.flow_average_bandwidth_Mbps:
            for flow_cookie in self.flow_average_bandwidth_Mbps[port_num]:
                flow_average_switch_load += self.flow_average_bandwidth_Mbps[port_num][flow_cookie]
        self.flow_average_switch_load = flow_average_switch_load

        # Update last response time
        complete_processing_time = time.time()
        self._last_flow_stats_query_processing_time = complete_processing_time - reception_time
        self._last_flow_stats_query_total_time = complete_processing_time - self._last_flow_stats_query_send_time

        # Print log information to file
        if not self.flow_tracker._log_file is None:
            self.flow_tracker._log_file.write('FlowStats Switch:' + dpid_to_str(self.dpid) + ' NumFlows:' + str(
                self.num_flows) + ' IntervalLen:' + str(interval_len) + ' IntervalEndTime:' + str(
                reception_time) + ' ResponseTime:' + str(
                self._last_flow_stats_query_total_time) + ' NetworkTime:' + str(
                self._last_flow_stats_query_network_time) + ' ProcessingTime:' + str(
                self._last_flow_stats_query_processing_time) + ' AvgSwitchLoad:' + str(
                self.flow_average_switch_load) + '\n')

            for port_num in self.flow_interval_bandwidth_Mbps:
                for flow_cookie in self.flow_interval_bandwidth_Mbps[port_num]:
                    self.flow_tracker._log_file.write(
                        'Port:' + str(port_num) + ' FlowCookie: ' + str(flow_cookie) + ' BytesThisInterval:' + str(
                            self.flow_interval_byte_count[port_num][flow_cookie])
                        + ' InstBandwidth:' + str(
                            self.flow_interval_bandwidth_Mbps[port_num][flow_cookie]) + ' AvgBandwidth:' + str(
                            self.flow_average_bandwidth_Mbps[port_num][flow_cookie]) + '\n')

            self.flow_tracker._log_file.write('\n')

        self._last_flow_stats_query_response_time = reception_time


class FlowTracker(EventMixin):
    """Module which implements bandwidth utilization tracking by managing a map of FlowTrackedSwitches."""
    _core_name = "openflow_flow_tracker"

    def __init__(self, query_interval, link_max_bw, link_cong_threshold, avg_smooth_factor, log_peak_usage):
        """Initializes the FlowTracker module, and configures all required listener's once dependencies have loaded.

        Initialization parameters:
        query_interval: The time interval (in seconds) between subsequent queries to a particular switch
        link_max_bw: The maximum supported bandwidth of links in the network in Mbps (all tracked links must have uniform
                     bandwidth in the current implementation, due to limitations of OpenFlow 1.0).
        link_cong_threshold: The threshold above which links are considered to be congested in Mbps.
        avg_smooth_factor: The alpha value used for exponential average smoothing of bandwidth estimations
        log_peak_usage: If true, periodically output peak and average link usage to log.info
        """
        # Listen to dependencies
        def startup():
            core.openflow.addListeners(self, priority=101)
            core.openflow_discovery.addListeners(self, priority=101)
            core.openflow_igmp_manager.addListeners(self, priority=101)
            self._module_init_time = time.time()
            self._log_file_name = datetime.datetime.now().strftime("flowtracker_%H-%M-%S_%B-%d_%Y.txt")
            log.info('Writing flow tracker info to file: ' + str(self._log_file_name))
            self._log_file = open(self._log_file_name, 'w') # TODO: Figure out how to properly close this on shutdown

        self._got_first_connection = False  # Flag used to start the periodic query thread when the first ConnectionUp is received
        self._peak_usage_output_timer = None

        self.periodic_query_interval_seconds = float(query_interval)
        self.link_max_bw = float(link_max_bw)
        self.link_cong_threshold = float(link_cong_threshold)
        self.avg_smooth_factor = float(avg_smooth_factor)
        self.log_peak_usage = float(log_peak_usage)

        log.info('Set QueryInterval:' + str(self.periodic_query_interval_seconds) + ' LinkMaxBw:' + str(
            self.link_max_bw) + 'Mbps LinkCongThreshold:' + str(self.link_cong_threshold)
                 + 'Mbps AvgSmoothFactor:' + str(self.avg_smooth_factor) + ' LogPeakUsage:' + str(self.log_peak_usage))

        self._module_init_time = 0
        self._log_file = None
        self._log_file_name = None

        # Map is keyed by dpid
        self.switches = {}

        # Setup listeners
        core.call_when_ready(startup, ('openflow', 'openflow_igmp_manager', 'openflow_discovery'))

    def termination_handler(self, signal, frame):
        """Method to cleanly terminate the module (i.e. close the log file) when a SIGINT signal is received.

        This function is typically called by the BenchmarkTerminator module."""
        if not self._log_file is None:
            self._log_file.close()
            self._log_file = None
            log.info('Termination signalled, closed log file: ' + str(self._log_file_name))

    def output_peak_usage(self):
        """Outputs the current peak utilization and average link utilization to log.info"""
        peak_usage = 0
        total_usage = 0
        num_links = 0
        for switch_dpid in self.switches:
            if not self.switches[switch_dpid].is_connected:
                continue

            for port_no in self.switches[switch_dpid].flow_average_bandwidth_Mbps:
                if port_no == of.OFPP_LOCAL or port_no == of.OFPP_CONTROLLER:
                    continue
                total_usage += self.switches[switch_dpid].port_average_bandwidth_Mbps[port_no]
                num_links += 1
                if self.switches[switch_dpid].port_average_bandwidth_Mbps[port_no] > peak_usage:
                    peak_usage = self.switches[switch_dpid].port_average_bandwidth_Mbps[port_no]

        log.info('Network peak link throughout (Mbps): ' + str(peak_usage))
        if num_links > 0:
            log.info('Network avg link throughout (Mbps): ' + str(total_usage / float(num_links)))

    def _handle_ConnectionUp(self, event):
        """Handler for ConnectionUp from the discovery module, which represents a new switche joining the network."""
        if not event.dpid in self.switches:
            # New switch
            switch = FlowTrackedSwitch(self)
            switch.dpid = event.dpid
            self.switches[event.dpid] = switch
            log.debug('Learned new switch: ' + dpid_to_str(switch.dpid))
            switch.listen_on_connection(event.connection)
        else:
            log.debug('Restablished connection with switch: ' + dpid_to_str(event.dpid))
            self.switches[event.dpid].listen_on_connection(event.connection)

        if not self._got_first_connection:
            self._got_first_connection = True
            if self.log_peak_usage:
                self._peak_usage_output_timer = Timer(self.periodic_query_interval_seconds / 1.5, self.output_peak_usage
                    , recurring=True)

    def _handle_ConnectionDown(self, event):
        """Handler for ConnectionDown from the discovery module, which represents a switch leaving the network."""
        switch = self.switches.get(event.dpid)
        if switch is None:
            log.debug('Got ConnectionDown for unrecognized switch')
        else:
            log.debug('Lost connection with switch: ' + dpid_to_str(event.dpid))
            switch.ignore_connection()

    def _handle_FlowStatsReceived(self, event):
        """Forwards the flow statistics contained in the FlowStats event to the appropriate FlowTrackedSwitch."""
        if event.connection.dpid in self.switches:
            self.switches[event.connection.dpid].process_flow_stats(event.stats, time.time())

    def _handle_PortStatsReceived(self, event):
        """Forwards the port statistics contained in the FlowStats event to the appropriate FlowTrackedSwitch."""
        if event.connection.dpid in self.switches:
            self.switches[event.connection.dpid].process_port_stats(event.stats, time.time())

    def _handle_MulticastTopoEvent(self, event):
        """Processes a topology event generated by the IGMPManager module, and enables utilization tracking on all inter-switch links."""
        for switch1 in event.adjacency_map:
            if switch1 in self.switches:
                tracked_ports = []
                for switch2 in event.adjacency_map[switch1]:
                    if event.adjacency_map[switch1][switch2] is not None:
                        tracked_ports.append(event.adjacency_map[switch1][switch2])
                self.switches[switch1].set_tracked_ports(tracked_ports)

    def get_link_utilization_mbps(self, switch_dpid, output_port):
        """Returns the current estimated utilization (in Mbps) on the specified switch and output port.

        If a utilization is available based on port stats from the receive side of the specified link, this value will
        be returned (as port stats are more reliable in Mininet than flow stats). If port stats are not available (which
        would occur when the opposite side of the link is not being tracked) then a utilization estimate derived from
        flow stats will be returned.
        """
        # First, get the switch on the other side of this link
        receive_switch_dpid = None
        receive_port = None
        for link in core.openflow_discovery.adjacency:
            if link.dpid1 == switch_dpid and link.port1 == output_port:
                receive_switch_dpid = link.dpid2
                receive_port = link.port2
                break

        if receive_switch_dpid is None:
            # Reception statistics unavailable, use the transmission statistics if available
            log.warn("PortStats unavailable for Switch: " + dpid_to_str(switch_dpid) + ' Port: ' + str(output_port))
            if switch_dpid in self.switches:
                if output_port in self.switches[switch_dpid].port_average_bandwidth_Mbps:
                    bandwidth_total = 0
                    for flow_cookie in self.switches[switch_dpid].port_average_bandwidth_Mbps[output_port]:
                        bandwidth_total += self.switches[switch_dpid].port_average_bandwidth_Mbps[output_port][flow_cookie]
                    return bandwidth_total
            return 0    # TODO: May want to throw exception here

        if receive_switch_dpid in self.switches:
            if receive_port in self.switches[receive_switch_dpid].port_average_bandwidth_Mbps:
                return self.switches[receive_switch_dpid].port_average_bandwidth_Mbps[receive_port]

        return 0    # TODO: May want to throw exception here

    def get_link_utilization_normalized(self, switch_dpid, output_port):
        """Returns the current estimated utilization (as a normalized value between 0 and 1) on the specified switch and output port.

        Note: Current implementation assumes all links have equal maximum bandwidth which is defined by self.link_max_bw"""
        return self.get_link_utilization_mbps(switch_dpid, output_port) / self.link_max_bw


def launch(query_interval=PERIODIC_QUERY_INTERVAL, link_max_bw=LINK_MAX_BANDWIDTH_MbPS,
           link_cong_threshold=LINK_CONGESTION_THRESHOLD_MbPS, avg_smooth_factor=AVERAGE_SMOOTHING_FACTOR,
           log_peak_usage=False):
    flow_tracker = FlowTracker(float(query_interval), float(link_max_bw), float(link_cong_threshold),
        float(avg_smooth_factor), bool(log_peak_usage))
    core.register('openflow_flow_tracker', flow_tracker)